---
aliases: 
- CoT или не CoT 
date: 30-Jun-2025
tags:
- 2025/Jun
- кейсы/ансамблирование
- разработка/код/семантическая_разметка
- промптинг/техники/альтернативные
- промптинг/классификация_задач
- llm/архитектура/генерация/авторегрессия
- llm/концепция/сравнение/автокомплит
- промптинг/техники/cot/критика
topics:
- .
---
-----
##  CoT или не CoT 
-----
Недавнее исследование Apple о вреде техники Chain of Thought (CoT) для некоторых задач не является новостью для опытных специалистов, в отличие от тех, кто ошибочно считает GPT продвинутым «автокомплитом».

Механика CoT действительно позволяет ИИ глубже анализировать сложные задачи, заставляя его рассуждать пошагово. Однако этот же процесс (авторегрессия) снижает надёжность ответа в ситуациях, где решение очевидно, и модель сразу находит сильную корреляцию.

В таких случаях, которые в научном промптинге называют «простыми» (например, поиск корреляций), CoT действительно вреден. Но более эффективной альтернативой является не просто отказ от него, а применение продвинутых методов, таких как однотокенный промптинг, который даёт ещё более качественный результат.

---
## Zero-links
---
- [[0 События и инициативы]]
- [[0 Теория авторегрессии]]
- [[0 Принципы и модели мышления ИИ]]
- [[0 Техники создания подсказок (Промптинг)]]

---
## Links
---
- [Source](https://t.me/turboproject/1735)
- https://machinelearning.apple.com/research/illusion-of-thinking