---
aliases: 
- О тщетности борьбы с природой языковых моделей
tags:
- 2025/Oct
- ai/llm/optimization/performance_cost
- llm/development/tool_calling
- llm/optimization/token_usage
- llm/training/reinforcement_learning
- llm/development/best_practices
author:
- Vladimir Ivanov
---
![[reinforcement learning на Tool.png]]

-----
##  О тщетности борьбы с природой языковых моделей 
-----
Эксперт утверждает, что замена нативных функций вызова инструментов (Tools) в языковых моделях (LLM), таких как Gemini и Qwen, на кастомные методы через JSON-схемы приводит к снижению их производительности и увеличению стоимости из-за большего расхода токенов. 

Это происходит потому, что такие «кустарные» подходы противоречат заложенным в модели механизмам обучения с подкреплением (reinforcement learning).

Автор рекомендует не отказываться от нативных режимов, а при необходимости помогать ИИ с выбором инструмента с помощью инструкций.

---
## Zero-links
---
- [[0 Фундаментальные архитектуры и их компоненты]]
- [[0 Фундаментальные технологии и принципы]]
- [[0 Техники адаптации моделей]]
- [[0 Характеристики ИИ-модели]]

---
## Links
---
- [Source №1](https://t.me/turboproject/2286)
- [Source №2](https://t.me/turboproject/2287)