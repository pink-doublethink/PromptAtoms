---
aliases: 
- Q — не вопрос, K — не ответ 
date: 28-Jun-2025
tags:
- 2025/Apr
- ИИ/архитектура/attention/матрицы_qk_цель
- llm/архитектура/attention/матрицы_qk_сходств
- Семантика/attention/матрицы_qk
- llm/архитектура/мифы/упрощения
- ИИ/архитектура/attention/миф_q_k
topics:
- .
---
![[Q — не вопрос, K — не ответ.jpg]]

-----
##  Q — не вопрос, K — не ответ 
-----
  
Текст предостерегает от упрощенных и популярных объяснений работы GPT, которые часто вводят в заблуждение. Основная цель — развенчать распространённый миф о механизме внимания в трансформере.

Вопреки популярному мнению, матрицы Q (Query) и K (Key) не являются аналогами «вопросов» и «ответов». Это заблуждение, поскольку на самом деле они выполняют общую, симметричную задачу: проецируют векторы слов в единое смысловое подпространство для поиска корреляций. После обучения Q и K становятся схожи на 90%, и модель эффективно работает даже при их полном равенстве.

Их реальная функция едина, а небольшое различие между ними служит лишь для технической цели — ослабления ненужных связей между токенами, а не для разделения ролей.

---
## Zero-links
---
-  [[0 Механизмы внимания]]

---
## Links
---
- [Source](https://t.me/turboproject/1597)