---
aliases: 
- Когда машина учится сомневаться
tags:
- 2025/Oct
- ai/llm/reliability/hallucinations
- ai/llm/evaluation/confidence
- ai/llm/reliability/uncertainty-expression
- ai/llm/evaluation/self-assessment
- ai/llm/evaluation/self-assessment-accuracy
author:
- Vladimir Ivanov
---
-----
##  Когда машина учится сомневаться 
-----
Для борьбы с «галлюцинациями» (вымыслами) языковых моделей предлагается новый подход: вместо обучения ответу «я не знаю», что неэффективно для малых моделей, следует использовать промптинг для оценки уверенности модели в собственном ответе. 

Эксперименты показывают, что самооценка (рефлексия) ИИ своей уверенности оказывается на удивление точной при правильно сформулированном запросе.

---
## Zero-links
---
- [[0 Эмерджентные явления и новое поведение]]
- [[0 Техники адаптации моделей]]
- [[0 Характеристики ИИ-модели]]
- [[0 Техники создания подсказок (Промптинг)]]
- [[0 Принципы и модели мышления ИИ]]
- [[0 Внутренние процессы и состояния модели]]

---
## Links
---
- [Source]()
- https://www.arxiv.org/abs/2509.25760