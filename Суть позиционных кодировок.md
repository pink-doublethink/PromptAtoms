---
aliases:
- Скрытая половина «мозгов» GPT
tags:
- 2025/May
- ai/llm/architecture/positional-encodings
- ai/llm/theory/semantics
- ai/llm/data-representation/structure
- ai/llm/theory/semantic-fractal
- ai/llm/interpretability/positional-encodings
- ai/llm/theory/syntax-semantics
author:
- Vladimir Ivanov
---
![[половина.jpg]]

-----
##  Суть позиционных кодировок 
-----
Позиционные кодировки — это критически важный, но малоизученный аспект работы GPT, составляющий до половины семантической основы модели. Их главная задача — определять положение данных внутри вложенных, периодических структур. Например, в тексте это позиция слова в предложении, абзаце и главе, а в коде — иерархия синтаксиса.

Эти кодировки цикличны и формируют «семантический фрактал», который GPT использует для генерации ответов. Сложность их понимания кроется в «интерференции семантики»: модель одновременно применяет сотни кодировок, чтобы гибко управлять связью между структурой (синтаксисом) и смыслом (семантикой).

---
## Zero-links
---
- [[0 Структуры данных и модели знаний]]
- [[0 Структурные и семантические подходы]]
- [[0 Внутренние процессы и состояния модели]]
- [[0 Теоретические концепции и модели работы ИИ]]
- [[0 Фундаментальные архитектуры и их компоненты]]

---
## Links
---
- [Source](https://t.me/turboproject/1655)