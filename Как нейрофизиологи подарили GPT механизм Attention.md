---
aliases: 
- Как нейрофизиологи подарили GPT механизм Attention 
tags:
- 2025/May
- ai/neuroscience
- ai/neuroscience/brain-computer-analogy
- ai/neural-networks/architectures
- ai/nlp/attention
- nlp/attention
- ai/history
author:
- Vladimir Ivanov
---
-----
##  Как нейрофизиологи подарили GPT механизм Attention 
-----
Прорывы в искусственном интеллекте часто вдохновлены исследованиями мозга. Например, сверточные нейросети для зрения были созданы по образу зрительной системы человека.

Менее известен тот факт, что схожая история стоит и за прорывом в текстовых моделях, подобных GPT. В то время как разработчики ИИ использовали последовательные модели (RNN), когнитивисты выяснили, что мозг человека обрабатывает текст иначе — параллельно, с активным использованием периферийного зрения.

Именно нейрофизиологическая модель чтения Easy Reader еще в начале 2000-х годов представила механизм, ставший важнейшим источником вдохновения для Attention — технологии, которая лежит в основе современных языковых моделей.

---
## Zero-links
---
- [[0 ИИ-модели и системы]]
- [[0 Механизмы внимания]]
- [[0 Теоретические концепции и модели работы ИИ]]
- [[0 Профессиональные группы и роли]]
- [[0 Фундаментальные архитектуры и их компоненты]]

---
## Links
---
- [Source](https://t.me/turboproject/1702)
- https://ru.wikipedia.org/wiki/E-Z_Reader