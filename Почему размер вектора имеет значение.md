---
aliases: 
- Почему размер вектора имеет значение 
date: 30-Jun-2025
tags:
- 2025/Jun
- .
topics:
- .
---
![[снижении размерности.jpg]]

-----
##  Почему размер вектора имеет значение 
-----
Большой размер векторов в современных GPT (10 000+ измерений) — это прямое решение проблемы, известной как «катастрофа суперпозиции». При низкой размерности вектора попытка объединить несколько смыслов (например, «яблоко» и «груша») приводит к их смешению в бессмысленного «мутанта», из-за чего нейросеть теряет исходные понятия и начинает галлюцинировать.

Огромное количество измерений позволяет реализовать «суперпозицию смыслов» без этой катастрофы. В таком многомерном пространстве можно уместить тысячи понятий в один вектор, поскольку каждое из них сохранит уникальность хотя бы в одном из измерений, что позволяет модели их различать.

Вывод прост: следует с осторожностью относиться к нейросетям с малой размерностью векторов, особенно к «импортозамещенным» решениям, так как они рискуют столкнуться с «катастрофой суперпозиции», что делает их ненадёжными.

---
## Zero-links
---
- ....

---
## Links
---
- [Source](https://t.me/turboproject/1752)
- https://link.springer.com/article/10.1007/s11571-023-10061-1