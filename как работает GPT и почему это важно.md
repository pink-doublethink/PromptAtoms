---
aliases: 
- как работает GPT и почему это важно 
tags:
- 2025/Apr
- ai/llm/architecture
- ai/llm/limitations
- ai/llm/data-processing/semantics
- data/semantics
- ai/llm/data-processing/non-linear-text
- ai/llm/data-processing/chronology
author:
- Vladimir Ivanov
---
-----
##  как работает GPT и почему это важно 
-----
AI (GPT) обрабатывает текст строго последовательно, токен за токеном, основываясь только на предшествующей информации. Это означает, что его понимание уже прочитанного "высечено в камне" и не меняется от последующих данных, что легко приводит к "семантической катастрофе" при нарушении порядка. 

Такая авторегрессивная модель хорошо работает с хронологическими форматами вроде литературы или чатов. Но при нелинейной подаче, например, в коде (декларации после использования) или с глоссариями в конце, возникают проблемы: 

ИИ строит догадки и не пересматривает их, даже если они ошибочны, неспособный исправить ранние ошибки на основе поздних данных. Категорически важно подавать определения и информацию хронологически по тексту.

---
## Zero-links
---
- [[0 Внутренние процессы и состояния модели]]
- [[0 Фундаментальные технологии и принципы]]
- [[0 Образовательные подходы]]

---
## Links
---
- [Source](https://t.me/turboproject/1589)
- https://arxiv.org/abs/1904.09751