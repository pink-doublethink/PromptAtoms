---
aliases: 
- Причины провала SLM 
tags:
- 2025/Sep
- ai/future_agents
- ai/llm_research/slm_vs_llm
- ai/economics/market_trends
- ai/llm_architecture/innovations
- ai/economics/deployment_feasibility
- research/critique
author:
- Vladimir Ivanov
---
-----
##  Причины наблюдаемого провала малых SLM против LLM на MoE в AI-агентах 
-----
Статья оспаривает тезис [Belcak et al. (2025)](https://www.google.com/url?sa=E&q=https://vk.com/away.php?to=https%3A%2F%2Farxiv.org%2Fhtml%2F2506.02153v1&cc_key=) о том, что будущее ИИ-агентов принадлежит малым языковым моделям (SLM). Автор утверждает, что эта идея преждевременна и опровергается как рыночными данными, так и технологическими инновациями.

**Основные контраргументы:**

1. **Рыночные данные против SLM.** Статистика платформы OpenRouter показывает, что разработчики агентных систем предпочитают не SLM, а эффективные модели среднего размера (GPT-4.1 Mini, Claude Sonnet, Gemini Flash). В отраслевых решениях (финансы, здравоохранение) наблюдается полный отказ от SLM в пользу более мощных моделей.
    
2. **Технологическое превосходство LLM.** Экономическое преимущество SLM (низкая стоимость вычислений) нивелируется новыми архитектурами. Современные LLM с технологиями **Mixture-of-Experts (MoE)** и **Multi-Token Prediction (MTP)**, как Qwen3-Next, предлагают качество огромной модели при вычислительных затратах, сопоставимых с SLM, что делает выбор в их пользу очевидным.
    
3. **Экономическая нецелесообразность.** Даже для простых задач самостоятельное развертывание SLM проигрывает щедрым бесплатным или сверхдешевым API от крупных провайдеров (например, Gemini Flash). Использование API избавляет от затрат на поддержку собственной инфраструктуры, что делает его более выгодным.
    

**Вывод:** Будущее ИИ-агентов не за переходом на SLM, а за дальнейшей оптимизацией крупных моделей, особенно высокоэффективных LLM с архитектурой MoE. Ниша для SLM сохранится только в специфических областях (например, edge-computing, задачи с экстремальной приватностью), но они не станут мейнстримом.

---
## Zero-links
---
- [[0 ИИ-модели и системы]]
- [[0 Фундаментальные архитектуры и их компоненты]]
- [[0 Платформы, бенчмарки и стандарты]]

---
## Links
---
- [Source](https://vk.com/@-28685100-prichiny-nabludaemogo-provala-malyh-slm-protiv-llm-na-moe-v)