---
aliases: 
- почему разнятся научные оценки CoT в малых языковых моделях
tags:
- 2025/Sep
- ai/language_models/chain_of_thought
- ai/language_models/training_scaling
- ai/language_models/reasoning_abilities
- ai/language_models/slm_limitations
author:
- Vladimir Ivanov
---
![[никакого CoT для SLM.png]]

-----
##  почему разнятся научные оценки CoT в малых языковых моделях. 
-----
Противоречивые оценки эффективности метода Chain-of-Thought (CoT) для малых языковых моделей (SLM) объясняются разницей в их обучении. В отличие от крупных моделей, которые учатся логике рассуждений, SLM часто обучаются через дистилляцию, просто копируя текст ответа от модели-учителя. 

В результате SLM успешно имитируют CoT на стандартных тестах, для которых они "выучили решения", но не способны к реальным рассуждениям в новых, нетипичных задачах.

---
## Zero-links
---
- [[0 Платформы, бенчмарки и стандарты]]
- [[0 ИИ-модели и системы]]
- [[0 Техники создания подсказок (Промптинг)]]

---
## Links
---
- [Source](https://t.me/turboproject/2140)
- https://arxiv.org/html/2502.12143v1