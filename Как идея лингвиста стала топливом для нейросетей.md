---
aliases: 
- Как идея лингвиста стала топливом для нейросетей 
date: 30-Jun-2025
tags:
- 2025/Jun
- ИИ/история/семантические_векторы/прорывы
- ИИ/история/семантические_векторы/эволюция
- ИИ/история/междисциплинарность
- ИИ/история/семантические_векторы
topics:
- .
---
-----
##  Как идея лингвиста стала топливом для нейросетей 
-----
Концепция семантического вектора, лежащая в основе современного ИИ, имеет долгую историю, которая началась задолго до эпохи нейросетей — в лингвистике.

Путь начался в 1957 году, когда Джон Фёрс сформулировал идею, что слово можно понять по его окружению. В 1970-х Джерард Солтон уже применял векторную модель для семантического поиска по документам. Конкретно для слов векторы-эмбеддинги появились в конце 1980-х в рамках латентно-семантического анализа (LSA), но эффективного способа их получения ещё не было.

Настоящий прорыв произошёл, когда мир лингвистики встретился с миром нейросетей. В 2003 году Йошуа Бенжио доказал, что нейросети могут эффективно генерировать смысловые векторы, а в 2013-м Томаш Миколов создал Word2Vec, представив технологию в её современном виде.

Таким образом, идея, десятилетиями зревшая в лингвистике, лишь недавно объединилась с вычислительной мощью нейросетей, что привело к эпохальным открытиям, свидетелями которых мы являемся.

---
## Zero-links
---
- [[0 Фундаментальные архитектуры и их компоненты]]
- [[0 Фундаментальные технологии и принципы]]
- [[0 Теоретические концепции и модели работы ИИ]]
- [[0 Структуры данных и модели знаний]]

---
## Links
---
- [Source](https://t.me/turboproject/1757)
- https://en.wikipedia.org/wiki/Distributional_semantics